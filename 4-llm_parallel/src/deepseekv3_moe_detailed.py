"""
DeepSeek-V3 MoEæ¨¡å—è¯¦ç»†å®ç°
åŒ…å«è¯¦ç»†æ³¨é‡Šã€å¯è§†åŒ–æµç¨‹å›¾å’Œè¾“å…¥è¾“å‡ºå®ä¾‹

ä½œè€…: åŸºäºDeepSeek-V3è®ºæ–‡å®ç°
æ—¥æœŸ: 2024
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from typing import Tuple, Optional
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class DeepseekV3MLP(nn.Module):
    """
    DeepSeek-V3 MLPä¸“å®¶æ¨¡å—
    æ¯ä¸ªä¸“å®¶éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„MLPï¼Œä½¿ç”¨SwiGLUæ¿€æ´»å‡½æ•°
    """
    
    def __init__(self, config, hidden_size=None, intermediate_size=None):
        super().__init__()
        self.config = config
        self.hidden_size = config.hidden_size if hidden_size is None else hidden_size
        self.intermediate_size = (
            config.intermediate_size if intermediate_size is None else intermediate_size
        )
        
        # SwiGLUæ¿€æ´»å‡½æ•°çš„å‰å‘æŠ•å½±å±‚
        self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)
        self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)
        self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size, bias=False)
        self.act_fn = F.silu  # SwiGLUæ¿€æ´»å‡½æ•°
        
        print(f"ğŸ”§ åˆ›å»ºMLPä¸“å®¶: hidden_size={self.hidden_size}, intermediate_size={self.intermediate_size}")

    def forward(self, x):
        """
        SwiGLUæ¿€æ´»å‡½æ•°: SwiGLU(x) = SiLU(xW_gate) âŠ™ (xW_up)
        """
        gate_output = self.act_fn(self.gate_proj(x))  # SiLUæ¿€æ´»
        up_output = self.up_proj(x)  # çº¿æ€§å˜æ¢
        combined = gate_output * up_output  # é€å…ƒç´ ç›¸ä¹˜
        output = self.down_proj(combined)  # è¾“å‡ºæŠ•å½±
        return output

class MoEGate(nn.Module):
    """
    MoEé—¨æ§ç½‘ç»œ - ç®€åŒ–ç‰ˆæœ¬ç”¨äºæ¼”ç¤º
    """
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.top_k = config.num_experts_per_tok
        self.n_routed_experts = config.n_routed_experts
        self.weight = nn.Parameter(torch.randn(self.n_routed_experts, config.hidden_size))
        
    def forward(self, hidden_states):
        bsz, seq_len, h = hidden_states.shape
        hidden_states = hidden_states.view(-1, h)
        
        # è®¡ç®—é—¨æ§åˆ†æ•°
        logits = F.linear(hidden_states, self.weight)
        scores = logits.sigmoid()
        
        # é€‰æ‹©top-kä¸“å®¶
        _, topk_idx = torch.topk(scores, k=self.top_k, dim=-1, sorted=False)
        topk_weight = scores.gather(1, topk_idx)
        
        # å½’ä¸€åŒ–æƒé‡
        if self.top_k > 1:
            denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20
            topk_weight = topk_weight / denominator
            
        return topk_idx, topk_weight

class DeepseekV3MoE(nn.Module):
    """
    DeepSeek-V3 æ··åˆä¸“å®¶æ¨¡å—
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. é€šè¿‡é—¨æ§ç½‘ç»œä¸ºæ¯ä¸ªtokené€‰æ‹©åˆé€‚çš„ä¸“å®¶
    2. å¹¶è¡Œå¤„ç†æ‰€æœ‰tokençš„ä¸“å®¶è®¡ç®—
    3. åŠ æƒèšåˆä¸“å®¶è¾“å‡º
    4. æ”¯æŒå…±äº«ä¸“å®¶æœºåˆ¶
    
    ä¸»è¦ç‰¹ç‚¹:
    - æ”¯æŒä¸“å®¶å¹¶è¡Œ(EP)è®­ç»ƒ
    - é«˜æ•ˆçš„æ¨ç†ä¼˜åŒ–
    - å…±äº«ä¸“å®¶å¢å¼ºé€šç”¨èƒ½åŠ›
    """
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.num_experts_per_tok = config.num_experts_per_tok
        
        print(f"ğŸš€ åˆå§‹åŒ–DeepSeek-V3 MoEæ¨¡å—:")
        print(f"   - æ€»ä¸“å®¶æ•°: {config.n_routed_experts}")
        print(f"   - æ¯ä¸ªtokené€‰æ‹©ä¸“å®¶æ•°: {config.num_experts_per_tok}")
        print(f"   - ä¸“å®¶ä¸­é—´å±‚å¤§å°: {config.moe_intermediate_size}")
        
        # ä¸“å®¶å¹¶è¡Œé…ç½®
        if hasattr(config, "ep_size") and config.ep_size > 1:
            # å¤šGPUä¸“å®¶å¹¶è¡Œ
            self.ep_size = config.ep_size
            self.experts_per_rank = config.n_routed_experts // config.ep_size
            self.ep_rank = 0  # ç®€åŒ–ç‰ˆæœ¬ï¼Œå‡è®¾å•GPU
            print(f"   - ä¸“å®¶å¹¶è¡Œå¤§å°: {self.ep_size}")
            print(f"   - æ¯ä¸ªrankä¸“å®¶æ•°: {self.experts_per_rank}")
        else:
            # å•GPUæ¨¡å¼
            self.ep_size = 1
            self.experts_per_rank = config.n_routed_experts
            self.ep_rank = 0
            print(f"   - å•GPUæ¨¡å¼")
        
        # åˆ›å»ºä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList([
            DeepseekV3MLP(
                config, 
                intermediate_size=config.moe_intermediate_size
            )
            for i in range(config.n_routed_experts)
        ])
        
        # é—¨æ§ç½‘ç»œ
        self.gate = MoEGate(config)
        
        # å…±äº«ä¸“å®¶ï¼ˆå¯é€‰ï¼‰
        if hasattr(config, 'n_shared_experts') and config.n_shared_experts is not None:
            intermediate_size = config.moe_intermediate_size * config.n_shared_experts
            self.shared_experts = DeepseekV3MLP(
                config=config, 
                intermediate_size=intermediate_size
            )
            print(f"   - å…±äº«ä¸“å®¶ä¸­é—´å±‚å¤§å°: {intermediate_size}")
        else:
            self.shared_experts = None
            print(f"   - æ— å…±äº«ä¸“å®¶")

    def forward(self, hidden_states):
        """
        MoEå‰å‘ä¼ æ’­
        
        Args:
            hidden_states: è¾“å…¥éšè—çŠ¶æ€ [batch_size, seq_len, hidden_size]
            
        Returns:
            è¾“å‡ºéšè—çŠ¶æ€ [batch_size, seq_len, hidden_size]
        """
        print(f"\nğŸ”„ DeepSeek-V3 MoEå‰å‘ä¼ æ’­å¼€å§‹:")
        print(f"   - è¾“å…¥å½¢çŠ¶: {hidden_states.shape}")
        
        # ä¿å­˜åŸå§‹å½¢çŠ¶å’Œè¾“å…¥
        identity = hidden_states
        orig_shape = hidden_states.shape
        
        # æ­¥éª¤1: é—¨æ§ç½‘ç»œè®¡ç®—è·¯ç”±å†³ç­–
        print(f"\nğŸ“Š æ­¥éª¤1: é—¨æ§ç½‘ç»œè®¡ç®—è·¯ç”±å†³ç­–")
        topk_idx, topk_weight = self.gate(hidden_states)
        print(f"   - ä¸“å®¶ç´¢å¼•å½¢çŠ¶: {topk_idx.shape}")
        print(f"   - ä¸“å®¶æƒé‡å½¢çŠ¶: {topk_weight.shape}")
        print(f"   - ç¬¬ä¸€ä¸ªtokené€‰æ‹©çš„ä¸“å®¶: {topk_idx[0].tolist()}")
        print(f"   - ç¬¬ä¸€ä¸ªtokençš„ä¸“å®¶æƒé‡: {topk_weight[0].tolist()}")
        
        # é‡å¡‘è¾“å…¥ä¸ºäºŒç»´
        hidden_states = hidden_states.view(-1, hidden_states.shape[-1])
        print(f"   - é‡å¡‘åè¾“å…¥å½¢çŠ¶: {hidden_states.shape}")
        
        # æ­¥éª¤2: æ¨ç†æ¨¡å¼ä¸‹çš„ä¸“å®¶è®¡ç®—
        print(f"\nğŸ¯ æ­¥éª¤2: æ¨ç†æ¨¡å¼ä¸“å®¶è®¡ç®—")
        if not self.training:
            y = self.moe_infer(hidden_states, topk_idx, topk_weight).view(*orig_shape)

        # æ­¥éª¤3: æ·»åŠ å…±äº«ä¸“å®¶è¾“å‡ºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.shared_experts is not None:
            print(f"\nğŸ”— æ­¥éª¤3: æ·»åŠ å…±äº«ä¸“å®¶è¾“å‡º")
            shared_output = self.shared_experts(identity)
            y = y + shared_output
            print(f"   - å…±äº«ä¸“å®¶è¾“å‡ºå½¢çŠ¶: {shared_output.shape}")
        
        print(f"\nâœ… MoEå‰å‘ä¼ æ’­å®Œæˆ")
        print(f"   - è¾“å‡ºå½¢çŠ¶: {y.shape}")
        
        return y

    @torch.no_grad()
    def moe_infer(self, x, topk_ids, topk_weight):
        """
        æ¨ç†æ¨¡å¼ä¸‹çš„ä¸“å®¶è®¡ç®—ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        æ ¸å¿ƒä¼˜åŒ–:
        1. æŒ‰ä¸“å®¶åˆ†ç»„å¤„ç†tokenï¼Œå‡å°‘å†…å­˜è®¿é—®
        2. æ‰¹é‡è®¡ç®—æé«˜GPUåˆ©ç”¨ç‡
        3. é¿å…é‡å¤è®¡ç®—
        """
        print(f"   - æ¨ç†æ¨¡å¼ä¸“å®¶è®¡ç®—å¼€å§‹")
        
        # æ­¥éª¤1: ç»Ÿè®¡æ¯ä¸ªä¸“å®¶å¤„ç†çš„tokenæ•°é‡
        cnts = topk_ids.new_zeros((topk_ids.shape[0], len(self.experts)))
        cnts.scatter_(1, topk_ids, 1)
        tokens_per_expert = cnts.sum(dim=0)
        print(f"   - æ¯ä¸ªä¸“å®¶å¤„ç†çš„tokenæ•°: {tokens_per_expert.tolist()}")
        print(f"   - æ´»è·ƒä¸“å®¶æ•°: {(tokens_per_expert > 0).sum().item()}")
        
        # æ­¥éª¤2: å¯¹tokenæŒ‰ä¸“å®¶IDæ’åº
        idxs = topk_ids.view(-1).argsort()
        sorted_tokens = x[idxs // topk_ids.shape[1]]
        print(f"   - æ’åºåtokenå½¢çŠ¶: {sorted_tokens.shape}")
        
        # æ­¥éª¤3: æŒ‰ä¸“å®¶åˆ†ç»„å¤„ç†
        outputs = []
        start_idx = 0
        
        for i, num_tokens in enumerate(tokens_per_expert):
            end_idx = start_idx + num_tokens
            if num_tokens == 0:
                continue
                
            # è·å–å½“å‰ä¸“å®¶
            expert = self.experts[i]
            tokens_for_this_expert = sorted_tokens[start_idx:end_idx]
            
            print(f"   - ä¸“å®¶{i}: å¤„ç†{num_tokens}ä¸ªtoken")
            
            # ä¸“å®¶å‰å‘ä¼ æ’­
            expert_out = expert(tokens_for_this_expert)
            outputs.append(expert_out)
            start_idx = end_idx
        
        # æ­¥éª¤4: åˆå¹¶æ‰€æœ‰ä¸“å®¶è¾“å‡º
        if len(outputs) > 0:
            outs = torch.cat(outputs, dim=0)
        else:
            outs = sorted_tokens.new_empty(0)
        
        print(f"   - åˆå¹¶åè¾“å‡ºå½¢çŠ¶: {outs.shape}")
        
        # æ­¥éª¤5: æ¢å¤åŸå§‹tokené¡ºåº
        new_x = torch.empty_like(outs)
        new_x[idxs] = outs
        
        # æ­¥éª¤6: åŠ æƒèšåˆ
        final_out = (
            new_x.view(*topk_ids.shape, -1)
            .type(topk_weight.dtype)
            .mul_(topk_weight.unsqueeze(dim=-1))
            .sum(dim=1)
            .type(new_x.dtype)
        )
        
        print(f"   - æœ€ç»ˆè¾“å‡ºå½¢çŠ¶: {final_out.shape}")
        return final_out

    def visualize_moe_process(self, hidden_states, save_path="moe_process_visualization.png"):
        """
        å¯è§†åŒ–MoEå¤„ç†è¿‡ç¨‹
        """
        print(f"\nğŸ¨ å¼€å§‹ç”ŸæˆMoEå¤„ç†è¿‡ç¨‹å¯è§†åŒ–...")
        
        # è·å–MoEå¤„ç†ç»“æœ
        with torch.no_grad():
            output = self.forward(hidden_states)
            topk_idx, topk_weight = self.gate(hidden_states)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('DeepSeek-V3 MoEå¤„ç†è¿‡ç¨‹å¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        # 1. ä¸“å®¶ä½¿ç”¨åˆ†å¸ƒ
        ax1 = axes[0, 0]
        expert_usage = torch.zeros(self.config.n_routed_experts)
        for idx in topk_idx.flatten():
            expert_usage[idx] += 1
        
        bars = ax1.bar(range(self.config.n_routed_experts), expert_usage.numpy(), 
                      alpha=0.7, color='skyblue', edgecolor='black')
        ax1.set_title('ä¸“å®¶ä½¿ç”¨åˆ†å¸ƒ')
        ax1.set_xlabel('ä¸“å®¶ç´¢å¼•')
        ax1.set_ylabel('ä½¿ç”¨æ¬¡æ•°')
        ax1.set_xticks(range(0, self.config.n_routed_experts, 32))
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            if expert_usage[i] > 0:
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{int(expert_usage[i])}', ha='center', va='bottom', fontsize=8)
        
        # 2. æƒé‡åˆ†å¸ƒçƒ­åŠ›å›¾
        ax2 = axes[0, 1]
        sns.heatmap(topk_weight[:min(20, topk_weight.shape[0])].numpy(), 
                   ax=ax2, cmap='YlOrRd', cbar_kws={'label': 'æƒé‡å€¼'})
        ax2.set_title('Token-ä¸“å®¶æƒé‡çƒ­åŠ›å›¾ (å‰20ä¸ªtoken)')
        ax2.set_xlabel('ä¸“å®¶ç´¢å¼•')
        ax2.set_ylabel('Tokenç´¢å¼•')
        
        # 3. è¾“å…¥è¾“å‡ºå¯¹æ¯”
        ax3 = axes[1, 0]
        bsz, seq_len, hidden_size = hidden_states.shape
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªtokenè¿›è¡Œå¯è§†åŒ–
        input_token = hidden_states[0, 0].detach().numpy()
        output_token = output[0, 0].detach().numpy()
        
        x_pos = np.arange(min(50, hidden_size))
        ax3.plot(x_pos, input_token[:50], 'b-', alpha=0.7, label='è¾“å…¥', linewidth=2)
        ax3.plot(x_pos, output_token[:50], 'r-', alpha=0.7, label='è¾“å‡º', linewidth=2)
        ax3.set_title('Tokenå‘é‡å¯¹æ¯” (å‰50ç»´)')
        ax3.set_xlabel('éšè—ç»´åº¦')
        ax3.set_ylabel('æ•°å€¼')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. MoEå¤„ç†æµç¨‹å›¾
        ax4 = axes[1, 1]
        ax4.set_xlim(0, 10)
        ax4.set_ylim(0, 8)
        ax4.axis('off')
        
        # ç»˜åˆ¶æµç¨‹å›¾
        steps = [
            ('è¾“å…¥\nHidden States', 1, 6, 'lightblue'),
            ('é—¨æ§ç½‘ç»œ\nè·¯ç”±å†³ç­–', 3, 6, 'lightyellow'),
            ('ä¸“å®¶å¹¶è¡Œ\nè®¡ç®—', 5, 6, 'lightgreen'),
            ('åŠ æƒèšåˆ\nè¾“å‡º', 7, 6, 'lightcoral'),
            ('å…±äº«ä¸“å®¶\nèåˆ', 9, 6, 'lightpink')
        ]
        
        for text, x, y, color in steps:
            rect = patches.Rectangle((x-0.5, y-0.5), 1, 1, linewidth=2, 
                                   edgecolor='black', facecolor=color, alpha=0.7)
            ax4.add_patch(rect)
            ax4.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold')
        
        # æ·»åŠ ç®­å¤´
        for i in range(len(steps)-1):
            ax4.arrow(steps[i][1]+0.5, steps[i][2], 1, 0, head_width=0.1, 
                     head_length=0.1, fc='black', ec='black')
        
        ax4.set_title('MoEå¤„ç†æµç¨‹')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

def create_moe_config():
    """
    åˆ›å»ºMoEé…ç½®å¯¹è±¡
    """
    class Config:
        def __init__(self):
            self.hidden_size = 7168  # éšè—å±‚ç»´åº¦
            self.intermediate_size = 18432  # æ ‡å‡†MLPä¸­é—´å±‚å¤§å°
            self.moe_intermediate_size = 2048  # MoEä¸“å®¶ä¸­é—´å±‚å¤§å°
            self.n_routed_experts = 256  # è·¯ç”±ä¸“å®¶æ•°é‡
            self.num_experts_per_tok = 8  # æ¯ä¸ªtokené€‰æ‹©çš„ä¸“å®¶æ•°
            self.n_shared_experts = 1  # å…±äº«ä¸“å®¶æ•°é‡
            self.norm_topk_prob = True  # æ˜¯å¦å½’ä¸€åŒ–top-kæ¦‚ç‡
    
    return Config()

def demo_deepseekv3_moe():
    """
    DeepSeek-V3 MoEæ¨¡å—æ¼”ç¤ºå‡½æ•°
    """
    print("=" * 80)
    print("ğŸš€ DeepSeek-V3 MoEæ¨¡å—æ¼”ç¤º")
    print("=" * 80)
    
    # åˆ›å»ºé…ç½®
    config = create_moe_config()
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   - éšè—å±‚ç»´åº¦: {config.hidden_size}")
    print(f"   - è·¯ç”±ä¸“å®¶æ•°: {config.n_routed_experts}")
    print(f"   - æ¯ä¸ªtokené€‰æ‹©ä¸“å®¶æ•°: {config.num_experts_per_tok}")
    print(f"   - ä¸“å®¶ä¸­é—´å±‚å¤§å°: {config.moe_intermediate_size}")
    print(f"   - å…±äº«ä¸“å®¶æ•°: {config.n_shared_experts}")
    
    # åˆ›å»ºMoEæ¨¡å—
    moe_module = DeepseekV3MoE(config)
    print(f"\nğŸ”§ MoEæ¨¡å—åˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    batch_size = 2
    seq_len = 8
    hidden_size = config.hidden_size
    
    hidden_states = torch.randn(batch_size, seq_len, hidden_size)
    print(f"\nğŸ“¥ ç¤ºä¾‹è¾“å…¥:")
    print(f"   - å½¢çŠ¶: {hidden_states.shape}")
    print(f"   - æ•°æ®ç±»å‹: {hidden_states.dtype}")
    print(f"   - æ•°å€¼èŒƒå›´: [{hidden_states.min():.4f}, {hidden_states.max():.4f}]")
    
    # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
    moe_module.eval()
    
    # æ‰§è¡Œå‰å‘ä¼ æ’­
    print(f"\nğŸ”„ æ‰§è¡ŒMoEå‰å‘ä¼ æ’­...")
    with torch.no_grad():
        output = moe_module(hidden_states)
    
    # åˆ†æç»“æœ
    print(f"\nğŸ“Š MoEå¤„ç†ç»“æœåˆ†æ:")
    print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"   - è¾“å‡ºæ•°å€¼èŒƒå›´: [{output.min():.4f}, {output.max():.4f}]")
    print(f"   - è¾“å…¥è¾“å‡ºå·®å¼‚: {torch.abs(output - hidden_states).mean():.6f}")
    
    # ç»Ÿè®¡ä¸“å®¶ä½¿ç”¨æƒ…å†µ
    with torch.no_grad():
        topk_idx, topk_weight = moe_module.gate(hidden_states)
    
    expert_usage = torch.zeros(config.n_routed_experts)
    for idx in topk_idx.flatten():
        expert_usage[idx] += 1
    
    print(f"\nğŸ¯ ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡:")
    print(f"   - è¢«ä½¿ç”¨çš„ä¸“å®¶æ•°: {(expert_usage > 0).sum().item()}")
    print(f"   - ä½¿ç”¨æœ€å¤šçš„ä¸“å®¶: {expert_usage.argmax().item()} (ä½¿ç”¨{expert_usage.max().item()}æ¬¡)")
    print(f"   - ä½¿ç”¨æœ€å°‘çš„ä¸“å®¶: {expert_usage.argmin().item()} (ä½¿ç”¨{expert_usage.min().item()}æ¬¡)")
    print(f"   - å¹³å‡æ¯ä¸ªä¸“å®¶ä½¿ç”¨æ¬¡æ•°: {expert_usage.mean():.2f}")
    
    # æ£€æŸ¥è´Ÿè½½å‡è¡¡
    print(f"\nâš–ï¸ è´Ÿè½½å‡è¡¡æ£€æŸ¥:")
    total_usage = expert_usage.sum()
    expected_usage = batch_size * seq_len * config.num_experts_per_tok
    print(f"   - æ€»ä¸“å®¶ä½¿ç”¨æ¬¡æ•°: {total_usage}")
    print(f"   - æœŸæœ›ä½¿ç”¨æ¬¡æ•°: {expected_usage}")
    print(f"   - è´Ÿè½½å‡è¡¡åº¦: {1 - abs(total_usage - expected_usage) / expected_usage:.4f}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print(f"\nğŸ¨ ç”ŸæˆMoEå¤„ç†è¿‡ç¨‹å¯è§†åŒ–...")
    moe_module.visualize_moe_process(hidden_states, save_path="deepseekv3_moe_visualization.png")
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    demo_deepseekv3_moe() 