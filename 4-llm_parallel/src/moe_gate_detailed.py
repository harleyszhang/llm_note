"""
DeepSeek-V3 MoEé—¨æ§æœºåˆ¶è¯¦ç»†å®ç°
åŒ…å«è¯¦ç»†æ³¨é‡Šã€å¯è§†åŒ–æµç¨‹å›¾å’Œè¾“å…¥è¾“å‡ºå®ä¾‹

ä½œè€…: åŸºäºDeepSeek-V3è®ºæ–‡å®ç°
æ—¥æœŸ: 2024
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
from typing import Tuple, Optional
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class MoEGate(nn.Module):
    """
    DeepSeek-V3 MoEé—¨æ§æœºåˆ¶å®ç°
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. è®¡ç®—æ¯ä¸ªtokenå¯¹æ¯ä¸ªä¸“å®¶çš„äº²å’Œåº¦åˆ†æ•°
    2. åŸºäºèŠ‚ç‚¹å—é™è·¯ç”±ç­–ç•¥é€‰æ‹©top-kä¸“å®¶
    3. å®ç°æ— è¾…åŠ©æŸå¤±çš„è´Ÿè½½å‡è¡¡
    
    ä¸»è¦åˆ›æ–°:
    - æ— è¾…åŠ©æŸå¤±è´Ÿè½½å‡è¡¡ç­–ç•¥
    - èŠ‚ç‚¹å—é™è·¯ç”±(æ¯ä¸ªtokenæœ€å¤šè·¯ç”±åˆ°4ä¸ªèŠ‚ç‚¹)
    - æ— tokenä¸¢å¼ƒæœºåˆ¶
    """
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–MoEé—¨æ§æ¨¡å—
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å…³é”®å‚æ•°:
                - num_experts_per_tok: æ¯ä¸ªtokenè·¯ç”±åˆ°çš„ä¸“å®¶æ•°é‡ (é»˜è®¤8)
                - n_routed_experts: æ€»ä¸“å®¶æ•°é‡ (é»˜è®¤64)
                - routed_scaling_factor: è·¯ç”±ç¼©æ”¾å› å­ (é»˜è®¤1.0)
                - scoring_func: è¯„åˆ†å‡½æ•°ç±»å‹ ("sigmoid")
                - topk_method: top-ké€‰æ‹©æ–¹æ³• ("noaux_tc")
                - n_group: ä¸“å®¶åˆ†ç»„æ•°é‡ (é»˜è®¤16)
                - topk_group: æ¯ä¸ªtokenæœ€å¤šè·¯ç”±åˆ°çš„èŠ‚ç‚¹æ•° (é»˜è®¤4)
                - norm_topk_prob: æ˜¯å¦å½’ä¸€åŒ–top-kæ¦‚ç‡
                - hidden_size: éšè—å±‚ç»´åº¦
        """
        super().__init__()
        self.config = config
        
        # æ ¸å¿ƒå‚æ•°
        self.top_k = config.num_experts_per_tok  # æ¯ä¸ªtokené€‰æ‹©çš„ä¸“å®¶æ•°: 8
        self.n_routed_experts = config.n_routed_experts  # æ€»ä¸“å®¶æ•°: 64
        self.routed_scaling_factor = config.routed_scaling_factor  # è·¯ç”±ç¼©æ”¾å› å­
        self.scoring_func = config.scoring_func  # è¯„åˆ†å‡½æ•°: "sigmoid"
        self.topk_method = config.topk_method  # top-kæ–¹æ³•: "noaux_tc"
        self.n_group = config.n_group  # ä¸“å®¶åˆ†ç»„æ•°: 16
        self.topk_group = config.topk_group  # æœ€å¤šè·¯ç”±èŠ‚ç‚¹æ•°: 4
        
        # ç®—æ³•å‚æ•°
        self.norm_topk_prob = config.norm_topk_prob  # æ˜¯å¦å½’ä¸€åŒ–æ¦‚ç‡
        self.gating_dim = config.hidden_size  # é—¨æ§ç»´åº¦
        
        # é—¨æ§æƒé‡çŸ©é˜µ: [n_routed_experts, hidden_size]
        # ç”¨äºè®¡ç®—æ¯ä¸ªtokenå¯¹æ¯ä¸ªä¸“å®¶çš„äº²å’Œåº¦åˆ†æ•°
        self.weight = nn.Parameter(
            torch.empty((self.n_routed_experts, self.gating_dim))
        )
        
        # ä¸“å®¶åˆ†æ•°ä¿®æ­£åç½® (ä»…ç”¨äºnoaux_tcæ–¹æ³•)
        # ç”¨äºå®ç°æ— è¾…åŠ©æŸå¤±çš„è´Ÿè½½å‡è¡¡
        if self.topk_method == "noaux_tc":
            self.e_score_correction_bias = nn.Parameter(
                torch.empty((self.n_routed_experts))
            )
        
        # åˆå§‹åŒ–å‚æ•°
        self.reset_parameters()
        
        print(f"ğŸ”§ MoEé—¨æ§åˆå§‹åŒ–å®Œæˆ:")
        print(f"   - æ€»ä¸“å®¶æ•°: {self.n_routed_experts}")
        print(f"   - æ¯ä¸ªtokené€‰æ‹©ä¸“å®¶æ•°: {self.top_k}")
        print(f"   - ä¸“å®¶åˆ†ç»„æ•°: {self.n_group}")
        print(f"   - æœ€å¤šè·¯ç”±èŠ‚ç‚¹æ•°: {self.topk_group}")
        print(f"   - é—¨æ§ç»´åº¦: {self.gating_dim}")

    def reset_parameters(self) -> None:
        """
        åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        
        ä½¿ç”¨Kaimingå‡åŒ€åˆå§‹åŒ–é—¨æ§æƒé‡ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§
        """
        import torch.nn.init as init
        
        # Kaimingå‡åŒ€åˆå§‹åŒ–é—¨æ§æƒé‡
        init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        
        # åˆå§‹åŒ–ä¸“å®¶åˆ†æ•°ä¿®æ­£åç½®
        if self.topk_method == "noaux_tc":
            nn.init.zeros_(self.e_score_correction_bias)
        
        print("âœ… å‚æ•°åˆå§‹åŒ–å®Œæˆ")

    def forward(self, hidden_states: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­: è®¡ç®—è·¯ç”±å†³ç­–
        
        Args:
            hidden_states: è¾“å…¥éšè—çŠ¶æ€ [batch_size, seq_len, hidden_size]
            
        Returns:
            topk_idx: é€‰æ‹©çš„ä¸“å®¶ç´¢å¼• [batch_size * seq_len, top_k]
            topk_weight: å¯¹åº”çš„æƒé‡ [batch_size * seq_len, top_k]
        """
        bsz, seq_len, h = hidden_states.shape
        
        print(f"\nğŸš€ MoEé—¨æ§å‰å‘ä¼ æ’­å¼€å§‹:")
        print(f"   - è¾“å…¥å½¢çŠ¶: {hidden_states.shape}")
        print(f"   - æ‰¹æ¬¡å¤§å°: {bsz}, åºåˆ—é•¿åº¦: {seq_len}, éšè—ç»´åº¦: {h}")
        
        # ==================== æ­¥éª¤1: è®¡ç®—é—¨æ§åˆ†æ•° ====================
        print(f"\nğŸ“Š æ­¥éª¤1: è®¡ç®—é—¨æ§åˆ†æ•°")
        
        # é‡å¡‘è¾“å…¥: [batch_size, seq_len, hidden_size] -> [batch_size * seq_len, hidden_size]
        hidden_states = hidden_states.view(-1, h)
        print(f"   - é‡å¡‘åå½¢çŠ¶: {hidden_states.shape}")
        
        # è®¡ç®—logits: [batch_size * seq_len, n_routed_experts]
        # ä½¿ç”¨çº¿æ€§å˜æ¢è®¡ç®—æ¯ä¸ªtokenå¯¹æ¯ä¸ªä¸“å®¶çš„äº²å’Œåº¦
        logits = F.linear(
            hidden_states.type(torch.float32), 
            self.weight.type(torch.float32), 
            None
        )
        print(f"   - Logitså½¢çŠ¶: {logits.shape}")
        print(f"   - Logitsç»Ÿè®¡: min={logits.min():.4f}, max={logits.max():.4f}, mean={logits.mean():.4f}")
        
        # åº”ç”¨æ¿€æ´»å‡½æ•°å¾—åˆ°æœ€ç»ˆåˆ†æ•°
        if self.scoring_func == "sigmoid":
            scores = logits.sigmoid()
        else:
            raise NotImplementedError(
                f"ä¸æ”¯æŒçš„è¯„åˆ†å‡½æ•°: {self.scoring_func}"
            )
        print(f"   - Sigmoidåˆ†æ•°ç»Ÿè®¡: min={scores.min():.4f}, max={scores.max():.4f}, mean={scores.mean():.4f}")
        
        # ==================== æ­¥éª¤2: é€‰æ‹©top-kä¸“å®¶ ====================
        print(f"\nğŸ¯ æ­¥éª¤2: é€‰æ‹©top-kä¸“å®¶ (æ–¹æ³•: {self.topk_method})")
        
        if self.topk_method == "noaux_tc":
            # ç¡®ä¿åœ¨æ¨ç†æ¨¡å¼ä¸‹è¿è¡Œ
            assert not self.training, "noaux_tcæ–¹æ³•ä»…æ”¯æŒæ¨ç†æ¨¡å¼"
            
            # åº”ç”¨ä¸“å®¶åˆ†æ•°ä¿®æ­£åç½® (è´Ÿè½½å‡è¡¡)
            scores_for_choice = scores.view(bsz * seq_len, -1) + self.e_score_correction_bias.unsqueeze(0)
            print(f"   - ä¿®æ­£ååˆ†æ•°å½¢çŠ¶: {scores_for_choice.shape}")
            print(f"   - ä¿®æ­£åç½®ç»Ÿè®¡: min={self.e_score_correction_bias.min():.4f}, max={self.e_score_correction_bias.max():.4f}")
            
            # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„ç»„åˆ†æ•°
            # å°†ä¸“å®¶æŒ‰èŠ‚ç‚¹åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªèŠ‚ç‚¹ä¸Šæœ€é«˜K_r/Mä¸ªä¸“å®¶çš„åˆ†æ•°ä¹‹å’Œ
            group_scores = (
                scores_for_choice.view(bsz * seq_len, self.n_group, -1)
                .topk(2, dim=-1)[0]  # é€‰æ‹©æ¯ä¸ªç»„å†…å‰2ä¸ªæœ€é«˜åˆ†æ•°
                .sum(dim=-1)  # æ±‚å’Œå¾—åˆ°ç»„åˆ†æ•°
            )  # [batch_size * seq_len, n_group]
            print(f"   - ç»„åˆ†æ•°å½¢çŠ¶: {group_scores.shape}")
            print(f"   - ç»„åˆ†æ•°ç»Ÿè®¡: min={group_scores.min():.4f}, max={group_scores.max():.4f}")
            
            # é€‰æ‹©top-k_groupä¸ªèŠ‚ç‚¹
            group_idx = torch.topk(
                group_scores, k=self.topk_group, dim=-1, sorted=False
            )[1]  # [batch_size * seq_len, topk_group]
            print(f"   - é€‰æ‹©çš„èŠ‚ç‚¹ç´¢å¼•å½¢çŠ¶: {group_idx.shape}")
            print(f"   - èŠ‚ç‚¹ç´¢å¼•èŒƒå›´: {group_idx.min()} - {group_idx.max()}")
            
            # åˆ›å»ºèŠ‚ç‚¹æ©ç 
            group_mask = torch.zeros_like(group_scores)  # [batch_size * seq_len, n_group]
            group_mask.scatter_(1, group_idx, 1)  # å°†é€‰ä¸­çš„èŠ‚ç‚¹æ ‡è®°ä¸º1
            print(f"   - èŠ‚ç‚¹æ©ç å½¢çŠ¶: {group_mask.shape}")
            print(f"   - é€‰ä¸­èŠ‚ç‚¹æ•°: {group_mask.sum().item()}")
            
            # åˆ›å»ºä¸“å®¶æ©ç 
            score_mask = (
                group_mask.unsqueeze(-1)
                .expand(
                    bsz * seq_len, self.n_group, self.n_routed_experts // self.n_group
                )
                .reshape(bsz * seq_len, -1)
            )  # [batch_size * seq_len, n_routed_experts]
            print(f"   - ä¸“å®¶æ©ç å½¢çŠ¶: {score_mask.shape}")
            print(f"   - å¯ç”¨ä¸“å®¶æ•°: {score_mask.sum().item()}")
            
            # åº”ç”¨æ©ç ï¼Œå°†æœªé€‰ä¸­èŠ‚ç‚¹çš„ä¸“å®¶åˆ†æ•°è®¾ä¸ºè´Ÿæ— ç©·
            tmp_scores = scores_for_choice.masked_fill(~score_mask.bool(), float("-inf"))
            print(f"   - æ©ç ååˆ†æ•°ç»Ÿè®¡: min={tmp_scores.min():.4f}, max={tmp_scores.max():.4f}")
            
            # é€‰æ‹©top-kä¸ªä¸“å®¶
            _, topk_idx = torch.topk(
                tmp_scores, k=self.top_k, dim=-1, sorted=False
            )
            topk_weight = scores.gather(1, topk_idx)
            print(f"   - é€‰æ‹©çš„ä¸“å®¶ç´¢å¼•å½¢çŠ¶: {topk_idx.shape}")
            print(f"   - ä¸“å®¶æƒé‡å½¢çŠ¶: {topk_weight.shape}")
            
        else:
            raise NotImplementedError(
                f"ä¸æ”¯æŒçš„TopKæ–¹æ³•: {self.topk_method}"
            )
        
        # ==================== æ­¥éª¤3: æƒé‡å½’ä¸€åŒ– ====================
        print(f"\nâš–ï¸ æ­¥éª¤3: æƒé‡å½’ä¸€åŒ–")
        
        # å¦‚æœé€‰æ‹©å¤šä¸ªä¸“å®¶ä¸”éœ€è¦å½’ä¸€åŒ–ï¼Œåˆ™è¿›è¡Œæ¦‚ç‡å½’ä¸€åŒ–
        if self.top_k > 1 and self.norm_topk_prob:
            denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20
            topk_weight = topk_weight / denominator
            print(f"   - å½’ä¸€åŒ–åæƒé‡ç»Ÿè®¡: min={topk_weight.min():.4f}, max={topk_weight.max():.4f}")
        
        # åº”ç”¨è·¯ç”±ç¼©æ”¾å› å­
        topk_weight = topk_weight * self.routed_scaling_factor
        print(f"   - ç¼©æ”¾åæƒé‡ç»Ÿè®¡: min={topk_weight.min():.4f}, max={topk_weight.max():.4f}")
        
        print(f"\nâœ… MoEé—¨æ§å‰å‘ä¼ æ’­å®Œæˆ")
        print(f"   - è¾“å‡ºä¸“å®¶ç´¢å¼•å½¢çŠ¶: {topk_idx.shape}")
        print(f"   - è¾“å‡ºæƒé‡å½¢çŠ¶: {topk_weight.shape}")
        
        return topk_idx, topk_weight

    def visualize_routing_process(self, hidden_states: torch.Tensor, save_path: str = "moe_routing.png"):
        """
        å¯è§†åŒ–MoEè·¯ç”±è¿‡ç¨‹
        
        Args:
            hidden_states: è¾“å…¥éšè—çŠ¶æ€
            save_path: ä¿å­˜è·¯å¾„
        """
        print(f"\nğŸ¨ å¼€å§‹ç”Ÿæˆè·¯ç”±è¿‡ç¨‹å¯è§†åŒ–...")
        
        # è·å–è·¯ç”±ç»“æœ
        with torch.no_grad():
            topk_idx, topk_weight = self.forward(hidden_states)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('DeepSeek-V3 MoEè·¯ç”±è¿‡ç¨‹å¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        # 1. ä¸“å®¶åˆ†å¸ƒçƒ­åŠ›å›¾
        ax1 = axes[0, 0]
        expert_usage = torch.zeros(self.n_routed_experts)
        for idx in topk_idx.flatten():
            expert_usage[idx] += 1
        
        sns.heatmap(
            expert_usage.view(self.n_group, -1).numpy(),
            ax=ax1,
            cmap='YlOrRd',
            annot=True,
            fmt='.0f',
            cbar_kws={'label': 'ä½¿ç”¨æ¬¡æ•°'}
        )
        ax1.set_title('ä¸“å®¶ä½¿ç”¨åˆ†å¸ƒçƒ­åŠ›å›¾')
        ax1.set_xlabel('ç»„å†…ä¸“å®¶ç´¢å¼•')
        ax1.set_ylabel('èŠ‚ç‚¹ç»„ç´¢å¼•')
        
        # 2. æƒé‡åˆ†å¸ƒç›´æ–¹å›¾
        ax2 = axes[0, 1]
        ax2.hist(topk_weight.flatten().numpy(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.set_title('ä¸“å®¶æƒé‡åˆ†å¸ƒ')
        ax2.set_xlabel('æƒé‡å€¼')
        ax2.set_ylabel('é¢‘æ¬¡')
        ax2.grid(True, alpha=0.3)
        
        # 3. èŠ‚ç‚¹é€‰æ‹©ç»Ÿè®¡
        ax3 = axes[1, 0]
        bsz, seq_len, _ = hidden_states.shape
        n_tokens = bsz * seq_len
        
        # è®¡ç®—æ¯ä¸ªtokené€‰æ‹©çš„èŠ‚ç‚¹åˆ†å¸ƒ
        with torch.no_grad():
            scores = F.linear(
                hidden_states.view(-1, self.gating_dim).type(torch.float32),
                self.weight.type(torch.float32),
                None
            ).sigmoid()
            
            scores_for_choice = scores + self.e_score_correction_bias.unsqueeze(0)
            group_scores = (
                scores_for_choice.view(n_tokens, self.n_group, -1)
                .topk(2, dim=-1)[0]
                .sum(dim=-1)
            )
            _, group_idx = torch.topk(group_scores, k=self.topk_group, dim=-1, sorted=False)
        
        # ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹è¢«é€‰æ‹©çš„æ¬¡æ•°
        node_usage = torch.zeros(self.n_group)
        for idx in group_idx.flatten():
            node_usage[idx] += 1
        
        bars = ax3.bar(range(self.n_group), node_usage.numpy(), color='lightgreen', alpha=0.7)
        ax3.set_title('èŠ‚ç‚¹é€‰æ‹©ç»Ÿè®¡')
        ax3.set_xlabel('èŠ‚ç‚¹ç´¢å¼•')
        ax3.set_ylabel('è¢«é€‰æ‹©æ¬¡æ•°')
        ax3.set_xticks(range(self.n_group))
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, node_usage.numpy()):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{int(value)}', ha='center', va='bottom')
        
        # 4. è·¯ç”±æµç¨‹å›¾
        ax4 = axes[1, 1]
        ax4.set_xlim(0, 10)
        ax4.set_ylim(0, 8)
        ax4.axis('off')
        
        # ç»˜åˆ¶æµç¨‹å›¾
        steps = [
            ('è¾“å…¥\nHidden States', 1, 6, 'lightblue'),
            ('è®¡ç®—\né—¨æ§åˆ†æ•°', 3, 6, 'lightyellow'),
            ('èŠ‚ç‚¹å—é™\nè·¯ç”±', 5, 6, 'lightgreen'),
            ('ä¸“å®¶é€‰æ‹©\nTop-K', 7, 6, 'lightcoral'),
            ('æƒé‡å½’ä¸€åŒ–', 9, 6, 'lightpink')
        ]
        
        for text, x, y, color in steps:
            rect = patches.Rectangle((x-0.5, y-0.5), 1, 1, linewidth=2, 
                                   edgecolor='black', facecolor=color, alpha=0.7)
            ax4.add_patch(rect)
            ax4.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold')
        
        # æ·»åŠ ç®­å¤´
        for i in range(len(steps)-1):
            ax4.arrow(steps[i][1]+0.5, steps[i][2], 1, 0, head_width=0.1, 
                     head_length=0.1, fc='black', ec='black')
        
        ax4.set_title('MoEè·¯ç”±æµç¨‹')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

def create_moe_config():
    """
    åˆ›å»ºMoEé…ç½®å¯¹è±¡
    
    Returns:
        é…ç½®å¯¹è±¡
    """
    class Config:
        def __init__(self):
            self.num_experts_per_tok = 8  # æ¯ä¸ªtokené€‰æ‹©çš„ä¸“å®¶æ•°
            self.n_routed_experts = 256    # æ€»ä¸“å®¶æ•°
            self.routed_scaling_factor = 1.0  # è·¯ç”±ç¼©æ”¾å› å­
            self.scoring_func = "sigmoid"  # è¯„åˆ†å‡½æ•°
            self.topk_method = "noaux_tc"  # top-kæ–¹æ³•
            self.n_group = 8  # ä¸“å®¶åˆ†ç»„æ•° (èŠ‚ç‚¹æ•°)
            self.topk_group = 4  # æ¯ä¸ªtokenæœ€å¤šè·¯ç”±åˆ°çš„èŠ‚ç‚¹æ•°
            self.norm_topk_prob = True  # æ˜¯å¦å½’ä¸€åŒ–æ¦‚ç‡
            self.hidden_size = 7168  # éšè—å±‚ç»´åº¦
    
    return Config()

def demo_moe_gate():
    """
    MoEé—¨æ§æœºåˆ¶æ¼”ç¤ºå‡½æ•°
    """
    print("=" * 80)
    print("ğŸš€ DeepSeek-V3 MoEé—¨æ§æœºåˆ¶æ¼”ç¤º")
    print("=" * 80)
    
    # åˆ›å»ºé…ç½®
    config = create_moe_config()
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   - æ€»ä¸“å®¶æ•°: {config.n_routed_experts}")
    print(f"   - æ¯ä¸ªtokené€‰æ‹©ä¸“å®¶æ•°: {config.num_experts_per_tok}")
    print(f"   - ä¸“å®¶åˆ†ç»„æ•°: {config.n_group}")
    print(f"   - æœ€å¤šè·¯ç”±èŠ‚ç‚¹æ•°: {config.topk_group}")
    print(f"   - éšè—å±‚ç»´åº¦: {config.hidden_size}")
    
    # åˆ›å»ºMoEé—¨æ§æ¨¡å—
    moe_gate = MoEGate(config)
    print(f"\nğŸ”§ MoEé—¨æ§æ¨¡å—åˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    batch_size = 4
    seq_len = 64
    hidden_size = config.hidden_size
    
    hidden_states = torch.randn(batch_size, seq_len, hidden_size)
    print(f"\nğŸ“¥ ç¤ºä¾‹è¾“å…¥:")
    print(f"   - å½¢çŠ¶: {hidden_states.shape}")
    print(f"   - æ•°æ®ç±»å‹: {hidden_states.dtype}")
    print(f"   - æ•°å€¼èŒƒå›´: [{hidden_states.min():.4f}, {hidden_states.max():.4f}]")
    
    # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
    moe_gate.eval()
    
    # æ‰§è¡Œå‰å‘ä¼ æ’­
    print(f"\nğŸ”„ æ‰§è¡Œå‰å‘ä¼ æ’­...")
    with torch.no_grad():
        topk_idx, topk_weight = moe_gate(hidden_states)
    
    # åˆ†æç»“æœ
    print(f"\nğŸ“Š è·¯ç”±ç»“æœåˆ†æ:")
    print(f"   - é€‰æ‹©çš„ä¸“å®¶ç´¢å¼•å½¢çŠ¶: {topk_idx.shape}")
    print(f"   - ä¸“å®¶æƒé‡å½¢çŠ¶: {topk_weight.shape}")
    
    # ç»Ÿè®¡ä¸“å®¶ä½¿ç”¨æƒ…å†µ
    expert_usage = torch.zeros(config.n_routed_experts)
    for idx in topk_idx.flatten():
        expert_usage[idx] += 1
    
    print(f"\nğŸ¯ ä¸“å®¶ä½¿ç”¨ç»Ÿè®¡:")
    print(f"   - è¢«ä½¿ç”¨çš„ä¸“å®¶æ•°: {(expert_usage > 0).sum().item()}")
    print(f"   - ä½¿ç”¨æœ€å¤šçš„ä¸“å®¶: {expert_usage.argmax().item()} (ä½¿ç”¨{expert_usage.max().item()}æ¬¡)")
    print(f"   - ä½¿ç”¨æœ€å°‘çš„ä¸“å®¶: {expert_usage.argmin().item()} (ä½¿ç”¨{expert_usage.min().item()}æ¬¡)")
    
    # ç»Ÿè®¡æƒé‡åˆ†å¸ƒ
    print(f"\nâš–ï¸ æƒé‡åˆ†å¸ƒç»Ÿè®¡:")
    print(f"   - æƒé‡æœ€å°å€¼: {topk_weight.min():.4f}")
    print(f"   - æƒé‡æœ€å¤§å€¼: {topk_weight.max():.4f}")
    print(f"   - æƒé‡å¹³å‡å€¼: {topk_weight.mean():.4f}")
    print(f"   - æƒé‡æ ‡å‡†å·®: {topk_weight.std():.4f}")
    
    # æ£€æŸ¥è´Ÿè½½å‡è¡¡
    print(f"\nâš–ï¸ è´Ÿè½½å‡è¡¡æ£€æŸ¥:")
    total_usage = expert_usage.sum()
    expected_usage = batch_size * seq_len * config.num_experts_per_tok
    print(f"   - æ€»ä¸“å®¶ä½¿ç”¨æ¬¡æ•°: {total_usage}")
    print(f"   - æœŸæœ›ä½¿ç”¨æ¬¡æ•°: {expected_usage}")
    print(f"   - è´Ÿè½½å‡è¡¡åº¦: {1 - abs(total_usage - expected_usage) / expected_usage:.4f}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print(f"\nğŸ¨ ç”Ÿæˆè·¯ç”±è¿‡ç¨‹å¯è§†åŒ–...")
    moe_gate.visualize_routing_process(hidden_states, save_path="moe_routing_visualization.png")
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆ!")
    print("=" * 80)

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    demo_moe_gate() 